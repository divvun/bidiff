#[global_allocator]
static GLOBAL: mimalloc::MiMalloc = mimalloc::MiMalloc;

use anyhow::{Context, Result};
use bidiff::DiffParams;
use clap::Parser;
use memmap2::Mmap;
use std::{
    fs::File,
    io::{BufWriter, Write},
    path::PathBuf,
    time::Instant,
};
use tracing::info;

/// Generate and apply binary patches
#[derive(Parser, Debug)]
struct Cli {
    #[command(subcommand)]
    cmd: Command,
}

#[derive(clap::Subcommand, Debug)]
enum Command {
    /// Write the diff of two files to a patch file
    Diff(Diff),
    /// Apply a patch file generated by this tool
    Patch(Patch),
    /// Round-trip verification (diff then patch)
    Cycle(Cycle),
}

#[derive(Parser, Debug, Clone)]
struct Diff {
    older: PathBuf,
    newer: PathBuf,
    patch: PathBuf,
    /// Hash index block size (minimum 4)
    #[arg(long, default_value_t = 32)]
    block_size: usize,
    /// Scan chunk size in MB (default: 1)
    #[arg(long, default_value_t = 1)]
    scan_chunk_mb: usize,
    /// Max threads for parallel scanning (default: all cores)
    #[arg(long)]
    threads: Option<usize>,
    /// Maximize compression (zstd level 22); slower but ~30% smaller patches
    #[arg(long)]
    max: bool,
    /// Keep hash table in RAM (faster but uses ~500 MB+ for large files)
    #[arg(long)]
    ram: bool,
}

#[derive(Parser, Debug)]
struct Patch {
    older: PathBuf,
    patch: PathBuf,
    output: PathBuf,
}

#[derive(Parser, Debug)]
struct Cycle {
    older: PathBuf,
    newer: PathBuf,
    /// Hash index block size (minimum 4)
    #[arg(long, default_value_t = 32)]
    block_size: usize,
    /// Scan chunk size in MB (default: 1)
    #[arg(long, default_value_t = 1)]
    scan_chunk_mb: usize,
    /// Max threads for parallel scanning (default: all cores)
    #[arg(long)]
    threads: Option<usize>,
    /// Maximize compression (zstd level 22); slower but ~30% smaller patches
    #[arg(long)]
    max: bool,
    /// Keep hash table in RAM (faster but uses ~500 MB+ for large files)
    #[arg(long)]
    ram: bool,
    /// Also measure peak anonymous RSS (runs a separate diff pass with a polling thread)
    #[arg(long)]
    with_anon: bool,
}

/// Read anonymous RSS (heap + anonymous mmap) from /proc/self/status.
/// Excludes file-backed mmap pages — only counts "real" memory allocations.
fn read_rss_anon() -> u64 {
    std::fs::read_to_string("/proc/self/status")
        .ok()
        .and_then(|s| {
            s.lines()
                .find(|l| l.starts_with("RssAnon:"))?
                .split_whitespace()
                .nth(1)?
                .parse::<u64>()
                .ok()
        })
        .map(|kb| kb * 1024)
        .unwrap_or(0)
}

fn format_size(bytes: u64) -> String {
    if bytes >= 1024 * 1024 {
        format!("{:.1} MiB", bytes as f64 / (1024.0 * 1024.0))
    } else if bytes >= 1024 {
        format!("{:.0} KiB", bytes as f64 / 1024.0)
    } else {
        format!("{} B", bytes)
    }
}

fn main() -> Result<()> {
    tracing_subscriber::fmt::init();

    let Cli { cmd } = Cli::parse();
    match cmd {
        Command::Diff(args) => {
            do_diff(&args)?;
        }
        Command::Patch(args) => {
            do_patch(&args)?;
        }
        Command::Cycle(args) => {
            do_cycle(&args)?;
        }
    }

    Ok(())
}

fn do_cycle(
    Cycle {
        older,
        newer,
        block_size,
        scan_chunk_mb,
        threads,
        max,
        ram,
        with_anon,
    }: &Cycle,
) -> Result<()> {
    let newer_mmap = mmap_file(newer)?;
    info!(
        "Before {}, After {}",
        format_size(std::fs::metadata(older)?.len()),
        format_size(newer_mmap.len() as u64),
    );

    let diff_args = Diff {
        older: older.clone(),
        newer: newer.clone(),
        patch: PathBuf::new(), // filled in below
        block_size: *block_size,
        scan_chunk_mb: *scan_chunk_mb,
        threads: *threads,
        max: *max,
        ram: *ram,
    };

    // Separate anon RSS measurement pass (if requested) — uses a polling thread
    // so we don't contaminate the timing run.
    let peak_mem = if *with_anon {
        use std::sync::atomic::{AtomicBool, AtomicU64, Ordering};
        let peak_anon = std::sync::Arc::new(AtomicU64::new(0));
        let done = std::sync::Arc::new(AtomicBool::new(false));
        let peak_clone = peak_anon.clone();
        let done_clone = done.clone();
        std::thread::spawn(move || {
            while !done_clone.load(Ordering::Relaxed) {
                peak_clone.fetch_max(read_rss_anon(), Ordering::Relaxed);
                std::thread::sleep(std::time::Duration::from_millis(5));
            }
        });
        let anon_tmp = tempfile::NamedTempFile::new().context("create anon tempfile")?;
        do_diff(&Diff {
            patch: anon_tmp.path().to_path_buf(),
            ..diff_args.clone()
        })?;
        done.store(true, Ordering::Release);
        Some(peak_anon.load(Ordering::Acquire))
    } else {
        None
    };

    let patch_tmp = tempfile::NamedTempFile::new().context("create patch tempfile")?;
    let output_tmp = tempfile::NamedTempFile::new().context("create output tempfile")?;
    let patch_path = patch_tmp.path().to_path_buf();
    let output_path = output_tmp.path().to_path_buf();

    let before_diff = Instant::now();
    do_diff(&Diff {
        patch: patch_path.clone(),
        ..diff_args
    })?;
    let diff_duration = before_diff.elapsed();

    let compatch_size = std::fs::metadata(&patch_path)?.len();

    let before_patch = Instant::now();
    do_patch(&Patch {
        older: older.clone(),
        patch: patch_path,
        output: output_path.clone(),
    })?;
    let patch_duration = before_patch.elapsed();

    let fresh = mmap_file(&output_path)?;
    anyhow::ensure!(fresh.len() == newer_mmap.len(), "Size mismatch!");
    let newer_hash = blake3::hash(&newer_mmap[..]);
    let fresh_hash = blake3::hash(&fresh[..]);
    anyhow::ensure!(newer_hash == fresh_hash, "Hash mismatch!");

    let ratio = (compatch_size as f64) / (newer_mmap.len() as f64);
    let cp = format!("patch {}", format_size(compatch_size));
    let cr = format!(
        "{:03.3}% of {}",
        ratio * 100.0,
        format_size(newer_mmap.len() as u64)
    );
    let cdd = format!("dtime {:?}", diff_duration);
    let cpd = format!("ptime {:?}", patch_duration);
    if let Some(mem) = peak_mem {
        let cmem = format!("anon {}", format_size(mem));
        println!(
            "{:12} {:20} {:27} {:20} {:20} {:20}",
            "zstd", cp, cr, cdd, cpd, cmem
        );
    } else {
        println!("{:12} {:20} {:27} {:20} {:20}", "zstd", cp, cr, cdd, cpd);
    }

    Ok(())
}

fn do_patch(
    Patch {
        older,
        patch,
        output,
    }: &Patch,
) -> Result<()> {
    let start = Instant::now();

    // Mmap patch file directly — each chunk is independently compressed inside
    let patch_data = mmap_file(patch)?;

    // Parse chunked patch header (zero-copy: borrows slices from patch_data)
    let header = bidiff::patch::read_patch(&patch_data).context("read chunked patch header")?;
    let older = mmap_file(older)?;

    // Setup output mmap with fallocate + huge pages
    let output_file = File::options()
        .read(true)
        .write(true)
        .create(true)
        .truncate(true)
        .open(output)
        .context("create output file")?;
    #[cfg(target_os = "linux")]
    {
        use std::os::unix::io::AsRawFd;
        // fallocate pre-allocates disk blocks, avoiding per-page block allocation during writes.
        // Falls back to ftruncate on failure (e.g. tmpfs).
        if unsafe { libc::fallocate(output_file.as_raw_fd(), 0, 0, header.new_size as i64) } != 0 {
            output_file
                .set_len(header.new_size)
                .context("pre-size output file")?;
        }
    }
    #[cfg(not(target_os = "linux"))]
    output_file
        .set_len(header.new_size)
        .context("pre-size output file")?;
    let mut output_mmap =
        unsafe { memmap2::MmapMut::map_mut(&output_file) }.context("mmap output file")?;
    #[cfg(unix)]
    output_mmap.advise(memmap2::Advice::HugePage).ok();

    // Apply chunks in parallel using rayon's thread pool for bounded parallelism.
    let out = output_mmap.as_mut_ptr() as usize;
    let out_len = output_mmap.len();
    rayon::scope(|s| {
        for chunk in &header.chunks {
            let start = chunk.new_start as usize;
            let len = chunk.new_len as usize;
            assert!(start + len <= out_len);
            // SAFETY: each chunk writes to a non-overlapping region of the mmap.
            let output_slice =
                unsafe { std::slice::from_raw_parts_mut((out + start) as *mut u8, len) };
            let old_ref = &older[..];
            s.spawn(move |_| {
                bidiff::patch::apply_chunk(chunk, old_ref, output_slice).unwrap();
            });
        }
    });

    output_mmap.flush_async().context("flush output mmap")?;

    info!("Completed in {:?}", start.elapsed());

    Ok(())
}

fn mmap_file(path: &PathBuf) -> Result<Mmap> {
    let file = File::open(path).with_context(|| format!("open {}", path.display()))?;
    let mmap = unsafe { memmap2::MmapOptions::new().populate().map(&file) }
        .with_context(|| format!("mmap {}", path.display()))?;
    #[cfg(unix)]
    mmap.advise(memmap2::Advice::HugePage).ok();
    Ok(mmap)
}

fn do_diff(
    Diff {
        older,
        newer,
        patch,
        block_size,
        scan_chunk_mb,
        threads,
        max,
        ram,
    }: &Diff,
) -> Result<()> {
    let start = Instant::now();

    let older_contents = mmap_file(older)?;
    #[cfg(unix)]
    older_contents.advise(memmap2::Advice::Random).ok();
    let newer_contents = mmap_file(newer)?;
    #[cfg(unix)]
    newer_contents.advise(memmap2::Advice::Sequential).ok();

    let scan_chunk_size = Some(scan_chunk_mb * 1024 * 1024);
    let mut diff_params = DiffParams::with_threads(*block_size, scan_chunk_size, *threads).unwrap();
    diff_params.use_ram = *ram;
    let zstd_level = if *max { 22 } else { 3 };
    let mut out = BufWriter::new(File::create(patch).context("create patch file")?);
    bidiff::simple_diff_chunked_with_params(
        &older_contents[..],
        &newer_contents[..],
        &mut out,
        &diff_params,
        zstd_level,
    )
    .context("chunked diff")?;
    out.flush().context("finish writing patch file")?;

    info!("Completed in {:?}", start.elapsed());

    Ok(())
}
