#[global_allocator]
static GLOBAL: mimalloc::MiMalloc = mimalloc::MiMalloc;

use anyhow::{Context, Result};
use bidiff::DiffParams;
use clap::Parser;
use memmap2::Mmap;
use size::Size;
use std::{
    fs::File,
    io::{BufWriter, Write},
    path::PathBuf,
    time::Instant,
};
use tracing::info;

/// Generate and apply binary patches
#[derive(Parser, Debug)]
struct Cli {
    #[command(subcommand)]
    cmd: Command,
}

#[derive(clap::Subcommand, Debug)]
enum Command {
    /// Write the diff of two files to a patch file
    Diff(Diff),
    /// Apply a patch file generated by this tool
    Patch(Patch),
    /// Round-trip verification (diff then patch)
    Cycle(Cycle),
}

#[derive(Parser, Debug)]
struct Diff {
    older: PathBuf,
    newer: PathBuf,
    patch: PathBuf,
    /// Hash index block size (minimum 4)
    #[arg(long, default_value_t = 32)]
    block_size: usize,
    /// Optionally specify a chunk size
    #[arg(long)]
    scan_chunk_size: Option<usize>,
    /// Max threads for parallel scanning (default: all cores)
    #[arg(long)]
    threads: Option<usize>,
    /// Maximize compression (zstd level 22); slower but ~30% smaller patches
    #[arg(long)]
    max: bool,
}

#[derive(Parser, Debug)]
struct Patch {
    older: PathBuf,
    patch: PathBuf,
    output: PathBuf,
}

#[derive(Parser, Debug)]
struct Cycle {
    older: PathBuf,
    newer: PathBuf,
    /// Hash index block size (minimum 4)
    #[arg(long, default_value_t = 32)]
    block_size: usize,
    /// Optionally specify a chunk size
    #[arg(long)]
    scan_chunk_size: Option<usize>,
    /// Max threads for parallel scanning (default: all cores)
    #[arg(long)]
    threads: Option<usize>,
    /// Maximize compression (zstd level 22); slower but ~30% smaller patches
    #[arg(long)]
    max: bool,
}

fn main() -> Result<()> {
    tracing_subscriber::fmt::init();

    let Cli { cmd } = Cli::parse();
    match cmd {
        Command::Diff(args) => {
            do_diff(&args)?;
        }
        Command::Patch(args) => {
            do_patch(&args)?;
        }
        Command::Cycle(args) => {
            do_cycle(&args)?;
        }
    }

    Ok(())
}

fn do_cycle(
    Cycle {
        older,
        newer,
        block_size,
        scan_chunk_size,
        threads,
        max,
    }: &Cycle,
) -> Result<()> {
    let newer_mmap = mmap_file(newer)?;
    info!(
        "Before {}, After {}",
        Size::from_bytes(std::fs::metadata(older)?.len()),
        Size::from_bytes(newer_mmap.len()),
    );

    let patch_tmp = tempfile::NamedTempFile::new().context("create patch tempfile")?;
    let output_tmp = tempfile::NamedTempFile::new().context("create output tempfile")?;
    let patch_path = patch_tmp.path().to_path_buf();
    let output_path = output_tmp.path().to_path_buf();

    let before_diff = Instant::now();
    do_diff(&Diff {
        older: older.clone(),
        newer: newer.clone(),
        patch: patch_path.clone(),
        block_size: *block_size,
        scan_chunk_size: *scan_chunk_size,
        threads: *threads,
        max: *max,
    })?;
    let diff_duration = before_diff.elapsed();

    let compatch_size = std::fs::metadata(&patch_path)?.len();

    let before_patch = Instant::now();
    do_patch(&Patch {
        older: older.clone(),
        patch: patch_path,
        output: output_path.clone(),
    })?;
    let patch_duration = before_patch.elapsed();

    let fresh = mmap_file(&output_path)?;
    anyhow::ensure!(fresh.len() == newer_mmap.len(), "Size mismatch!");
    let newer_hash = blake3::hash(&newer_mmap[..]);
    let fresh_hash = blake3::hash(&fresh[..]);
    anyhow::ensure!(newer_hash == fresh_hash, "Hash mismatch!");

    let ratio = (compatch_size as f64) / (newer_mmap.len() as f64);
    let cp = format!("patch {}", Size::from_bytes(compatch_size as usize));
    let cr = format!(
        "{:03.3}% of {}",
        ratio * 100.0,
        Size::from_bytes(newer_mmap.len())
    );
    let cdd = format!("dtime {:?}", diff_duration);
    let cpd = format!("ptime {:?}", patch_duration);
    println!("{:12} {:20} {:27} {:20} {:20}", "zstd", cp, cr, cdd, cpd);

    Ok(())
}

fn do_patch(
    Patch {
        older,
        patch,
        output,
    }: &Patch,
) -> Result<()> {
    let start = Instant::now();

    // Mmap patch file directly â€” each chunk is independently compressed inside
    let patch_data = mmap_file(patch)?;

    // Parse chunked patch header (zero-copy: borrows slices from patch_data)
    let header = bidiff::patch::read_patch(&patch_data).context("read chunked patch header")?;
    let older = mmap_file(older)?;

    // Setup output mmap with fallocate + huge pages
    let output_file = File::options()
        .read(true)
        .write(true)
        .create(true)
        .truncate(true)
        .open(output)
        .context("create output file")?;
    #[cfg(target_os = "linux")]
    {
        use std::os::unix::io::AsRawFd;
        // fallocate pre-allocates disk blocks, avoiding per-page block allocation during writes.
        // Falls back to ftruncate on failure (e.g. tmpfs).
        if unsafe { libc::fallocate(output_file.as_raw_fd(), 0, 0, header.new_size as i64) } != 0 {
            output_file
                .set_len(header.new_size)
                .context("pre-size output file")?;
        }
    }
    #[cfg(not(target_os = "linux"))]
    output_file
        .set_len(header.new_size)
        .context("pre-size output file")?;
    let mut output_mmap =
        unsafe { memmap2::MmapMut::map_mut(&output_file) }.context("mmap output file")?;
    #[cfg(unix)]
    output_mmap.advise(memmap2::Advice::HugePage).ok();

    // Apply chunks in parallel using rayon's thread pool for bounded parallelism.
    let out = output_mmap.as_mut_ptr() as usize;
    let out_len = output_mmap.len();
    rayon::scope(|s| {
        for chunk in &header.chunks {
            let start = chunk.new_start as usize;
            let len = chunk.new_len as usize;
            assert!(start + len <= out_len);
            // SAFETY: each chunk writes to a non-overlapping region of the mmap.
            let output_slice =
                unsafe { std::slice::from_raw_parts_mut((out + start) as *mut u8, len) };
            let old_ref = &older[..];
            s.spawn(move |_| {
                bidiff::patch::apply_chunk(chunk, old_ref, output_slice).unwrap();
            });
        }
    });

    output_mmap.flush_async().context("flush output mmap")?;

    info!("Completed in {:?}", start.elapsed());

    Ok(())
}

fn mmap_file(path: &PathBuf) -> Result<Mmap> {
    let file = File::open(path).with_context(|| format!("open {}", path.display()))?;
    let mmap = unsafe { memmap2::MmapOptions::new().populate().map(&file) }
        .with_context(|| format!("mmap {}", path.display()))?;
    #[cfg(unix)]
    mmap.advise(memmap2::Advice::HugePage).ok();
    Ok(mmap)
}

fn do_diff(
    Diff {
        older,
        newer,
        patch,
        block_size,
        scan_chunk_size,
        threads,
        max,
    }: &Diff,
) -> Result<()> {
    let start = Instant::now();

    let older_contents = mmap_file(older)?;
    #[cfg(unix)]
    older_contents.advise(memmap2::Advice::Random).ok();
    let newer_contents = mmap_file(newer)?;
    #[cfg(unix)]
    newer_contents.advise(memmap2::Advice::Sequential).ok();

    let diff_params = DiffParams::with_threads(*block_size, *scan_chunk_size, *threads).unwrap();
    let zstd_level = if *max { 22 } else { 3 };
    let mut out = BufWriter::new(File::create(patch).context("create patch file")?);
    bidiff::simple_diff_chunked_with_params(
        &older_contents[..],
        &newer_contents[..],
        &mut out,
        &diff_params,
        zstd_level,
    )
    .context("chunked diff")?;
    out.flush().context("finish writing patch file")?;

    info!("Completed in {:?}", start.elapsed());

    Ok(())
}
